{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "import tempfile\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras import layers, Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "from keras import Model\n",
    "from keras.layers import Conv2D, PReLU,BatchNormalization, Flatten\n",
    "from keras.layers import UpSampling2D, LeakyReLU, Dense, Input, add\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the 100 HR images from Kaggle100-original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUCKET_NAME = 'srgan-wagon-project'\n",
    "STORAGE_LOCATION_hr = 'datasets/kaggle100-original/HR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_images_gcp(prefix):\n",
    "\n",
    "    client = storage.Client()\n",
    "\n",
    "    bucket = client.bucket(BUCKET_NAME)\n",
    "\n",
    "    blobs = bucket.list_blobs(prefix)\n",
    "    images = []\n",
    "\n",
    "    for blob in blobs:\n",
    "        _, temp_local_filename = tempfile.mkstemp()\n",
    "\n",
    "        # Download file from bucket.\n",
    "        blob.download_to_filename(temp_local_filename)\n",
    "        img = cv2.imread(temp_local_filename)\n",
    "        images.append(img)\n",
    "        os.remove(temp_local_filename)\n",
    "    return np.array(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_hr=get_images_gcp(prefix=STORAGE_LOCATION_hr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 384, 384, 3)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_hr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "plt.imshow(images_hr[0]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LR images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUCKET_NAME = 'srgan-wagon-project'\n",
    "STORAGE_LOCATION_LR = 'datasets/kaggle100-original/LR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_lr=get_images_gcp(prefix=STORAGE_LOCATION_LR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create X and Y and Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = images_lr/ 255\n",
    "y = images_hr/ 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- #Split to train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.33,\n",
    "                                                    random_state=42) -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Â Create Batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a list of images for LR and HR in batches from which a batch of images\n",
    "#would be fetched during training.\n",
    "batch_size = 1\n",
    "X_batches = []\n",
    "y_batches = []\n",
    "for it in range(int(y.shape[0] / batch_size)):\n",
    "    start_idx = it * batch_size\n",
    "    end_idx = start_idx + batch_size\n",
    "    y_batches.append(y[start_idx:end_idx])\n",
    "    X_batches.append(X[start_idx:end_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_shape = (y.shape[1], y.shape[2], y.shape[3])\n",
    "X_shape = (X.shape[1], X.shape[2], X.shape[3])\n",
    "\n",
    "X_ip = Input(shape=X_shape)\n",
    "y_ip = Input(shape=y_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def res_block(ip):\n",
    "\n",
    "    res_model = Conv2D(64, (3,3), padding = \"same\")(ip)\n",
    "    res_model = BatchNormalization(momentum = 0.5)(res_model)\n",
    "    res_model = PReLU(shared_axes = [1,2])(res_model)\n",
    "\n",
    "    res_model = Conv2D(64, (3,3), padding = \"same\")(res_model)\n",
    "    res_model = BatchNormalization(momentum = 0.5)(res_model)\n",
    "\n",
    "    return add([ip,res_model])\n",
    "\n",
    "def upscale_block(ip):\n",
    "\n",
    "    up_model = Conv2D(256, (3,3), padding=\"same\")(ip)\n",
    "    up_model = UpSampling2D( size = 2 )(up_model)\n",
    "    up_model = PReLU(shared_axes=[1,2])(up_model)\n",
    "\n",
    "    return up_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generator model\n",
    "def create_gen(gen_ip, num_res_block):\n",
    "    layers = Conv2D(64, (9,9), padding=\"same\")(gen_ip)\n",
    "    layers = PReLU(shared_axes=[1,2])(layers)\n",
    "\n",
    "    temp = layers\n",
    "\n",
    "    for i in range(num_res_block):\n",
    "        layers = res_block(layers)\n",
    "\n",
    "    layers = Conv2D(64, (3,3), padding=\"same\")(layers)\n",
    "    layers = BatchNormalization(momentum=0.5)(layers)\n",
    "    layers = add([layers,temp])\n",
    "\n",
    "    layers = upscale_block(layers)\n",
    "    layers = upscale_block(layers)\n",
    "\n",
    "    op = Conv2D(3, (9,9), padding=\"same\")(layers)\n",
    "\n",
    "    return Model(inputs=gen_ip, outputs=op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Descriminator block that will be used to construct the discriminator\n",
    "def discriminator_block(ip, filters, strides=1, bn=True):\n",
    "\n",
    "    disc_model = Conv2D(filters, (3,3), strides = strides, padding=\"same\")(ip)\n",
    "\n",
    "    if bn:\n",
    "        disc_model = BatchNormalization( momentum=0.8 )(disc_model)\n",
    "\n",
    "    disc_model = LeakyReLU( alpha=0.2 )(disc_model)\n",
    "\n",
    "    return disc_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Descriminartor, as described in the original paper\n",
    "def create_disc(disc_ip):\n",
    "\n",
    "    df = 64\n",
    "\n",
    "    d1 = discriminator_block(disc_ip, df, bn=False)\n",
    "    d2 = discriminator_block(d1, df, strides=2)\n",
    "    d3 = discriminator_block(d2, df*2)\n",
    "    d4 = discriminator_block(d3, df*2, strides=2)\n",
    "    d5 = discriminator_block(d4, df*4)\n",
    "    d6 = discriminator_block(d5, df*4, strides=2)\n",
    "    d7 = discriminator_block(d6, df*8)\n",
    "    d8 = discriminator_block(d7, df*8, strides=2)\n",
    "\n",
    "    d8_5 = Flatten()(d8)\n",
    "    d9 = Dense(df*16)(d8_5)\n",
    "    d10 = LeakyReLU(alpha=0.2)(d9)\n",
    "    validity = Dense(1, activation='sigmoid')(d10)\n",
    "\n",
    "    return Model(disc_ip, validity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import VGG19\n",
    "\n",
    "def build_vgg(y_shape):\n",
    "\n",
    "    vgg = VGG19(weights=\"imagenet\",include_top=False, input_shape=y_shape)\n",
    "\n",
    "    return Model(inputs=vgg.inputs, outputs=vgg.layers[10].output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combined model\n",
    "def create_comb(gen_model, disc_model, vgg, X_ip, y_ip):\n",
    "    gen_img = gen_model(X_ip)\n",
    "\n",
    "    gen_features = vgg(gen_img)\n",
    "\n",
    "    disc_model.trainable = False\n",
    "    validity = disc_model(gen_img)\n",
    "\n",
    "    return Model(inputs=[X_ip, y_ip], outputs=[validity, gen_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = create_gen(X_ip, num_res_block = 16)\n",
    "generator.summary()\n",
    "\n",
    "discriminator = create_disc(y_ip)\n",
    "discriminator.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])\n",
    "discriminator.summary()\n",
    "\n",
    "vgg = build_vgg((128,128,3))\n",
    "print(vgg.summary())\n",
    "vgg.trainable = False\n",
    "\n",
    "gan_model = create_comb(generator, discriminator, vgg, X_ip, y_ip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "#Enumerate training over epochs\n",
    "for e in range(epochs):\n",
    "\n",
    "    fake_label = np.zeros((batch_size, 1)) # Assign a label of 0 to all fake (generated images)\n",
    "    real_label = np.ones((batch_size,1)) # Assign a label of 1 to all real images.\n",
    "\n",
    "    #Create empty lists to populate gen and disc losses.\n",
    "    g_losses = []\n",
    "    d_losses = []\n",
    "\n",
    "    #Enumerate training over batches.\n",
    "    for b in tqdm(range(len(y_batches))):\n",
    "        X_imgs = X_batches[b] #Fetch a batch of LR images for training\n",
    "        y_imgs = y_batches[b] #Fetch a batch of HR images for training\n",
    "\n",
    "        fake_imgs = generator.predict_on_batch(X_imgs) #Fake images\n",
    "\n",
    "        #First, train the discriminator on fake and real HR images.\n",
    "        discriminator.trainable = True\n",
    "        d_loss_gen = discriminator.train_on_batch(fake_imgs, fake_label)\n",
    "        d_loss_real = discriminator.train_on_batch(y_imgs, real_label)\n",
    "\n",
    "        #Now, train the generator by fixing discriminator as non-trainable\n",
    "        discriminator.trainable = False\n",
    "\n",
    "        #Average the discriminator loss, just for reporting purposes.\n",
    "        d_loss = 0.5 * np.add(d_loss_gen, d_loss_real)\n",
    "\n",
    "        #Extract VGG features, to be used towards calculating loss\n",
    "        image_features = vgg.predict(y_imgs)\n",
    "\n",
    "        #Train the generator via GAN.\n",
    "        #Remember that we have 2 losses, adversarial loss and content (VGG) loss\n",
    "        g_loss, _, _ = gan_model.train_on_batch([X_imgs, y_imgs], [real_label, image_features])\n",
    "\n",
    "        #Save losses to a list so we can average and report.\n",
    "        d_losses.append(d_loss)\n",
    "        g_losses.append(g_loss)\n",
    "\n",
    "    #Convert the list of losses to an array to make it easy to average\n",
    "    g_losses = np.array(g_losses)\n",
    "    d_losses = np.array(d_losses)\n",
    "\n",
    "    #Calculate the average losses for generator and discriminator\n",
    "    g_loss = np.sum(g_losses, axis=0) / len(g_losses)\n",
    "    d_loss = np.sum(d_losses, axis=0) / len(d_losses)\n",
    "\n",
    "    #Report the progress during training.\n",
    "    print(\"epoch:\", e+1 ,\"g_loss:\", g_loss, \"d_loss:\", d_loss)\n",
    "\n",
    "    if (e+1) % 10 == 0: #Change the frequency for model saving, if needed\n",
    "        #Save the generator after every n epochs (Usually 10 epochs)\n",
    "        generator.save(\"gen_e_\"+ str(e+1) +\".h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('shims')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d26b7c0f89d12d86bcf5a1de10e59e02dca6c0d8322902beaf6a0a86f29f53b7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
